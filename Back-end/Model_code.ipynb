{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, WebSocket\n",
    "import whisper\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import tempfile\n",
    "import socket\n",
    "import threading\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Load Whisper model for transcription\n",
    "whisper_model_path = os.getenv(\"WHISPER_MODEL_PATH\", \"base\")\n",
    "whisper_model = whisper.load_model(whisper_model_path)\n",
    "\n",
    "# Load locally stored DeepSeek model for content correction\n",
    "deepseek_model_path = os.getenv(\"DEEPSEEK_MODEL_PATH\", \"./deepseek-3b\")\n",
    "deepseek_tokenizer = AutoTokenizer.from_pretrained(deepseek_model_path)\n",
    "deepseek_model = AutoModelForSeq2SeqLM.from_pretrained(deepseek_model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "def correct_text_local(text: str):\n",
    "    \"\"\"Runs DeepSeek locally for content correction.\"\"\"\n",
    "    inputs = deepseek_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
    "    outputs = deepseek_model.generate(**inputs, max_length=512)\n",
    "    corrected_text = deepseek_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "\n",
    "# Load summarization and translation models from Hugging Face\n",
    "tokenizer_summarization = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model_summarization = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "tokenizer_translation = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "model_translation = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "@app.websocket(\"/stream/\")\n",
    "async def stream_audio(websocket: WebSocket):\n",
    "    \"\"\"Handles real-time audio streaming.\"\"\"\n",
    "    await websocket.accept()\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as temp_audio:\n",
    "        while True:\n",
    "            try:\n",
    "                data = await websocket.receive_bytes()\n",
    "                temp_audio.write(data)\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "    # Transcribe the streamed audio\n",
    "    result = whisper_model.transcribe(temp_audio.name)\n",
    "    await websocket.send_json({\"transcription\": result[\"text\"]})\n",
    "    await websocket.close()\n",
    "\n",
    "@app.post(\"/correct/\")\n",
    "async def correct_text(text: str):\n",
    "    \"\"\"Corrects content using locally stored DeepSeek model.\"\"\"\n",
    "    corrected_text = correct_text_local(text)\n",
    "    return {\"corrected_text\": corrected_text}\n",
    "\n",
    "@app.post(\"/summarize/\")\n",
    "async def summarize_text(text: str):\n",
    "    \"\"\"Summarizes the given text.\"\"\"\n",
    "    inputs = tokenizer_summarization(text, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
    "    outputs = model_summarization.generate(**inputs, max_length=150, min_length=50, do_sample=False)\n",
    "    summary = tokenizer_summarization.decode(outputs[0], skip_special_tokens=True)\n",
    "    return {\"summary\": summary}\n",
    "\n",
    "@app.post(\"/translate/\")\n",
    "async def translate_text(text: str):\n",
    "    \"\"\"Translates text from English to French.\"\"\"\n",
    "    inputs = tokenizer_translation(text, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
    "    outputs = model_translation.generate(**inputs, max_length=512)\n",
    "    translated_text = tokenizer_translation.decode(outputs[0], skip_special_tokens=True)\n",
    "    return {\"translated_text\": translated_text}\n",
    "\n",
    "# Audio Streaming Server\n",
    "PORT = 5000  # Port for streaming\n",
    "\n",
    "def audio_stream_server():\n",
    "    \"\"\"Receives real-time audio data over a socket and saves it.\"\"\"\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((\"0.0.0.0\", PORT))\n",
    "    server_socket.listen(1)\n",
    "    print(f\"[STREAMING] Server listening on port {PORT}...\")\n",
    "    \n",
    "    conn, addr = server_socket.accept()\n",
    "    print(f\"[CONNECTED] Receiving stream from {addr}\")\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as temp_audio:\n",
    "        try:\n",
    "            while True:\n",
    "                data = conn.recv(1024)\n",
    "                if not data:\n",
    "                    break\n",
    "                temp_audio.write(data)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"[STOPPED] Streaming stopped.\")\n",
    "        finally:\n",
    "            conn.close()\n",
    "            server_socket.close()\n",
    "\n",
    "# Start the streaming server in a separate thread\n",
    "threading.Thread(target=audio_stream_server, daemon=True).start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
